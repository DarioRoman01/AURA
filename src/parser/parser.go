package parser

import (
	"aura/src/ast"
	l "aura/src/lexer"
	"fmt"
)

// Signature for functions to parse prefix expressions
type PrefixParsFn func() ast.Expression

// Signature for functions to parse suffix expressions
type SuffixParseFn func(ast.Expression) ast.Expression

// Signature for functions to parse infix expressions
type InfixParseFn func(ast.Expression) ast.Expression

type PrefixParsFns map[l.TokenType]PrefixParsFn
type InfixParseFns map[l.TokenType]InfixParseFn
type SuffixParseFns map[l.TokenType]SuffixParseFn

// represents the precedence of evaluation
type Precedence int

const (
	HeadPrecendence Precedence = iota
	LOWEST                     = 1
	ANDOR                      = 2
	EQUEAL                     = 3
	LESSGRATER                 = 4
	SUM                        = 5
	PRODUCT                    = 6
	PREFIX                     = 7
	CALL                       = 8
)

var PRECEDENCES = map[l.TokenType]Precedence{
	l.AND:         ANDOR,
	l.EQ:          EQUEAL,
	l.NOT_EQ:      EQUEAL,
	l.LT:          LESSGRATER,
	l.LTOREQ:      LESSGRATER,
	l.GT:          LESSGRATER,
	l.GTOREQ:      LESSGRATER,
	l.PLUS:        SUM,
	l.MINUS:       SUM,
	l.DIVISION:    PRODUCT,
	l.TIMES:       PRODUCT,
	l.MOD:         PRODUCT,
	l.LPAREN:      CALL,
	l.LBRACKET:    CALL,
	l.OR:          ANDOR,
	l.ASSING:      ANDOR,
	l.COLON:       CALL,
	l.PLUSASSING:  PRODUCT,
	l.MINUSASSING: PRODUCT,
	l.DIVASSING:   PRODUCT,
	l.EXPONENT:    PRODUCT,
	l.TIMEASSI:    PRODUCT,
	l.PLUS2:       PRODUCT,
	l.MINUS2:      PRODUCT,
}

// Represents the Parser of the programming lenguage
type Parser struct {
	lexer          *l.Lexer       // represents the lexer of the programming lenguage
	currentToken   *l.Token       // represents the current token in the parsing
	peekToken      *l.Token       // represnts the next token in the parsing
	errors         []string       // represents the error found while parsing
	prefixParsFns  PrefixParsFns  // represents all the functions to parse prefix expressions
	infixParseFns  InfixParseFns  // represents all the functions to parse infix expressions
	suffixParseFns SuffixParseFns // represents all the functions to parse suffix expressions
}

// generates a new parser instance
func NewParser(lexer *l.Lexer) *Parser {
	parser := &Parser{
		lexer:        lexer,
		currentToken: nil,
		peekToken:    nil,
	}

	// we register all the functions to parse the expressions
	parser.prefixParsFns = parser.registerPrefixFns()
	parser.infixParseFns = parser.registerInfixFns()
	parser.suffixParseFns = parser.registerSuffixFns()

	// we advance two times tokens to have a not nil first token
	parser.advanceTokens()
	parser.advanceTokens()
	return parser
}

// advance 1 in the tokens generated by the lexer
func (p *Parser) advanceTokens() {
	p.currentToken = p.peekToken
	nextToken := p.lexer.NextToken()
	p.peekToken = &nextToken
}

// check that the current token is not nil
func (p *Parser) checkCurrentTokenIsNotNil() {
	defer p.handlePeekTokenPanic()
	if p.currentToken == nil {
		panic("Ocurrio un error mientras se parseaba")
	}
}

// check that the peek token is not nil
func (p *Parser) checkPeekTokenIsNotNil() {
	defer p.handlePeekTokenPanic()
	if p.peekToken == nil {
		panic("Ocurrio un error mientras se parseaba")
	}
}

// handle a possible panic in the parser
func (p *Parser) handlePeekTokenPanic() {
	if r := recover(); r != nil {
		fmt.Println("Error: ", r)
	}
}

// return the precedence of the current token
func (p *Parser) currentPrecedence() Precedence {
	p.checkCurrentTokenIsNotNil()
	precedence, exists := PRECEDENCES[p.currentToken.Token_type]
	if !exists {
		return LOWEST
	}

	return precedence
}

// return the error list in the parser
func (p *Parser) Errors() []string {
	return p.errors
}

// parse all the program
func (p *Parser) ParseProgam() ast.Program {
	program := ast.Program{Staments: []ast.Stmt{}}

	for p.currentToken.Token_type != l.EOF {
		statement := p.parseStament()
		if statement != nil {
			program.Staments = append(program.Staments, statement)
		}

		p.advanceTokens()
	}
	return program
}

// expectedToken will check if the peek token is the correct type
// based on the parameter
func (p *Parser) expepectedToken(tokenType l.TokenType) bool {
	if p.peekToken.Token_type == tokenType {
		p.advanceTokens()
		return true
	}

	p.expectedTokenError(tokenType)
	return false
}

// add an error to errors list if there is any unexpected token error
func (p *Parser) expectedTokenError(tokenType l.TokenType) {
	p.checkCurrentTokenIsNotNil()
	err := fmt.Sprintf(
		"se esperaba que el siguient token fuera %s pero se obtuvo %s",
		l.Tokens[tokenType],
		l.Tokens[p.peekToken.Token_type],
	)
	p.errors = append(p.errors, err)
}

// parseBlock will parse a block expression
func (p *Parser) parseBlock() *ast.Block {
	p.checkCurrentTokenIsNotNil()
	blockStament := ast.NewBlock(*p.currentToken)
	p.advanceTokens()

	// we iterate until we find a } token
	for !(p.currentToken.Token_type == l.RBRACE) && !(p.currentToken.Token_type == l.EOF) {
		stament := p.parseStament()
		if stament != nil {
			blockStament.Staments = append(blockStament.Staments, stament)
		}

		p.advanceTokens()
	}

	return blockStament
}

// ParseArrayValues will parse all the values in array expressions
func (p *Parser) ParseArrayValues() []ast.Expression {
	p.checkCurrentTokenIsNotNil()
	var values []ast.Expression
	if p.peekToken.Token_type == l.RBRACKET {
		p.advanceTokens()
		return values
	}

	p.advanceTokens()
	if expression := p.parseExpression(LOWEST); expression != nil {
		values = append(values, expression)
	}

	for p.peekToken.Token_type == l.COMMA {
		p.advanceTokens()
		p.advanceTokens()
		if expression := p.parseExpression(LOWEST); expression != nil {
			values = append(values, expression)
		}
	}

	if !p.expepectedToken(l.RBRACKET) {
		return nil
	}

	return values
}

// parse all the arguments when a function is call
func (p *Parser) parseCallArguments() []ast.Expression {
	var args []ast.Expression
	p.checkPeekTokenIsNotNil()
	if p.peekToken.Token_type == l.RPAREN {
		// there is no arguemnts
		p.advanceTokens()
		return args
	}

	p.advanceTokens()
	if expression := p.parseExpression(LOWEST); expression != nil {
		args = append(args, expression)
	}

	// we loop until we dont have commas. this means whe parse all the values
	for p.peekToken.Token_type == l.COMMA {
		p.advanceTokens()
		p.advanceTokens()
		if expression := p.parseExpression(LOWEST); expression != nil {
			args = append(args, expression)
		}
	}

	if !p.expepectedToken(l.RPAREN) {
		return nil
	}

	return args
}

// parse a expression based on the given precedence
func (p *Parser) parseExpression(precedence Precedence) ast.Expression {
	defer p.handlePeekTokenPanic()
	p.checkCurrentTokenIsNotNil()

	// we check if there is any function to parse the current token
	prefixParseFn, exist := p.prefixParsFns[p.currentToken.Token_type]
	if !exist {
		// there is no function to parse the token
		message := fmt.Sprintf("no se encontro ninguna funcion para parsear %s", p.currentToken.Literal)
		p.errors = append(p.errors, message)
		return nil
	}

	leftExpression := prefixParseFn()
	p.checkPeekTokenIsNotNil()

	// we check if there is any suffix expression to be parsed
	if suffixFn, exists := p.suffixParseFns[p.peekToken.Token_type]; exists {
		p.advanceTokens()
		leftExpression = suffixFn(leftExpression)
		p.advanceTokens()
	}

	// we loop until the precedence is lowest than the next precedence
	for !(p.peekToken.Token_type == l.SEMICOLON) && precedence < p.peekPrecedence() {
		// we check if there is any function to parse an infix expression
		infixParseFn, exist := p.infixParseFns[p.peekToken.Token_type]
		if !exist {
			return leftExpression
		}

		p.advanceTokens()
		if leftExpression == nil {
			panic("Error de parseo")
		}

		leftExpression = infixParseFn(leftExpression)
	}

	return leftExpression
}

// parse a expression statement
func (p *Parser) parserExpressionStatement() *ast.ExpressionStament {
	p.checkCurrentTokenIsNotNil()
	expressionStament := ast.NewExpressionStament(*p.currentToken, nil)
	expressionStament.Expression = p.parseExpression(LOWEST)

	if p.peekToken == nil {
		panic("peek token cannot be bil")
	}
	if p.peekToken.Token_type == l.SEMICOLON {
		p.advanceTokens()
	}

	return expressionStament
}

// parse all the parameters of the function expresison
func (p *Parser) parseFunctionParameters() []*ast.Identifier {
	var params []*ast.Identifier
	p.checkPeekTokenIsNotNil()
	if p.peekToken.Token_type == l.RPAREN {
		// there is no parameters
		p.advanceTokens()
		return params
	}

	p.advanceTokens()
	identifier := ast.NewIdentifier(*p.currentToken, p.currentToken.Literal)
	params = append(params, identifier)

	// we loop until we dont have commas. this means we parse all the parameters
	for p.peekToken.Token_type == l.COMMA {
		p.advanceTokens()
		p.advanceTokens()
		identifier = ast.NewIdentifier(*p.currentToken, p.currentToken.Literal)
		params = append(params, identifier)
	}

	if !p.expepectedToken(l.RPAREN) {
		// syntax error
		return make([]*ast.Identifier, 0)
	}

	return params
}

// parse a suffix function
func (p *Parser) parseSuffixFn(left ast.Expression) ast.Expression {
	return ast.NewSuffix(*p.currentToken, left, p.currentToken.Literal)
}

// parse a null expression
func (p *Parser) ParseNull() ast.Expression {
	p.checkCurrentTokenIsNotNil()
	return ast.NewNull(*p.currentToken)
}

// parse a let statement
func (p *Parser) parseLetSatement() ast.Stmt {
	p.checkCurrentTokenIsNotNil()
	stament := ast.NewLetStatement(*p.currentToken, nil, nil)
	if !p.expepectedToken(l.IDENT) {
		return nil
	}

	stament.Name = p.parseIdentifier().(*ast.Identifier)
	if !p.expepectedToken(l.ASSING) {
		// syntax error. we dont allow this
		return nil
	}

	p.advanceTokens()
	stament.Value = p.parseExpression(LOWEST)
	p.checkPeekTokenIsNotNil()
	if p.peekToken.Token_type == l.SEMICOLON {
		p.advanceTokens()
	}

	return stament
}

// parse a return stament
func (p *Parser) parseReturnStatement() ast.Stmt {
	p.checkCurrentTokenIsNotNil()
	stament := ast.NewReturnStatement(*p.currentToken, nil)
	p.advanceTokens()

	stament.ReturnValue = p.parseExpression(LOWEST)
	p.checkPeekTokenIsNotNil()
	if p.peekToken.Token_type == l.SEMICOLON {
		p.advanceTokens()
	}

	return stament
}

// check current token and parse the token as a expression, let stament or return stament
func (p *Parser) parseStament() ast.Stmt {
	p.checkCurrentTokenIsNotNil()
	if p.currentToken.Token_type == l.LET {
		return p.parseLetSatement()
	} else if p.currentToken.Token_type == l.RETURN {
		return p.parseReturnStatement()
	}

	return p.parserExpressionStatement()
}

// return the precedence of the next token
func (p *Parser) peekPrecedence() Precedence {
	p.checkPeekTokenIsNotNil()
	precedence, exists := PRECEDENCES[p.peekToken.Token_type]
	if !exists {
		return LOWEST
	}

	return precedence
}

// register all the functions to parse infix expressions
func (p *Parser) registerInfixFns() InfixParseFns {
	inFixFns := make(InfixParseFns)
	inFixFns[l.PLUS] = p.parseInfixExpression
	inFixFns[l.MINUS] = p.parseInfixExpression
	inFixFns[l.COLON] = p.parseMethod
	inFixFns[l.DIVISION] = p.parseInfixExpression
	inFixFns[l.TIMES] = p.parseInfixExpression
	inFixFns[l.EQ] = p.parseInfixExpression
	inFixFns[l.NOT_EQ] = p.parseInfixExpression
	inFixFns[l.GTOREQ] = p.parseInfixExpression
	inFixFns[l.LTOREQ] = p.parseInfixExpression
	inFixFns[l.LT] = p.parseInfixExpression
	inFixFns[l.IN] = p.parseInfixExpression
	inFixFns[l.GT] = p.parseInfixExpression
	inFixFns[l.PLUSASSING] = p.parseInfixExpression
	inFixFns[l.MINUSASSING] = p.parseInfixExpression
	inFixFns[l.TIMEASSI] = p.parseInfixExpression
	inFixFns[l.DIVASSING] = p.parseInfixExpression
	inFixFns[l.EXPONENT] = p.parseInfixExpression
	inFixFns[l.LPAREN] = p.parseCall
	inFixFns[l.ASSING] = p.parseReassigment
	inFixFns[l.LBRACKET] = p.parseCallList
	inFixFns[l.MOD] = p.parseInfixExpression
	inFixFns[l.AND] = p.parseInfixExpression
	inFixFns[l.OR] = p.parseInfixExpression
	return inFixFns
}

// register all the functions to parse prefix expressions
func (p *Parser) registerPrefixFns() PrefixParsFns {
	prefixFns := make(PrefixParsFns)
	prefixFns[l.FALSE] = p.parseBoolean
	prefixFns[l.FOR] = p.parseFor
	prefixFns[l.FUNCTION] = p.parseFunction
	prefixFns[l.WHILE] = p.parseWhile
	prefixFns[l.IDENT] = p.parseIdentifier
	prefixFns[l.IF] = p.parseIf
	prefixFns[l.INT] = p.parseInteger
	prefixFns[l.LPAREN] = p.parseGroupExpression
	prefixFns[l.MINUS] = p.parsePrefixExpression
	prefixFns[l.NOT] = p.parsePrefixExpression
	prefixFns[l.TRUE] = p.parseBoolean
	prefixFns[l.STRING] = p.parseStringLiteral
	prefixFns[l.DATASTRCUT] = p.ParseArray
	prefixFns[l.NULLT] = p.ParseNull
	prefixFns[l.MAP] = p.parseMap
	prefixFns[l.FLOAT] = p.parseFloat
	return prefixFns
}

// register all the functions to parse suffix expressions
func (p *Parser) registerSuffixFns() SuffixParseFns {
	suffixFns := make(SuffixParseFns)
	suffixFns[l.EXPONENT] = p.parseSuffixFn
	suffixFns[l.PLUS2] = p.parseSuffixFn
	suffixFns[l.MINUS2] = p.parseSuffixFn
	return suffixFns
}
